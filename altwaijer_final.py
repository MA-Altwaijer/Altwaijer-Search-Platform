import streamlit as st
import pandas as pd
import google.generativeai as genai
import urllib.parse

# 1. ุฅุนุฏุงุฏุงุช ุงููุญุฑู ุงูุนุงููู
GEMINI_KEY = "AIzaSyDlB20oD63RlgMxF2Unfx7dqDjpwR2NM_U" 

# ูุฐุง ุงูุณุทุฑ ุชู ุชุนุฏููู ููุนูู ุจูุฌุฑุฏ ูุฌูุฏ ุงูููุชุงุญ
if GEMINI_KEY.startswith("AIza"):
    genai.configure(api_key=GEMINI_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')

# 2. ูุงุฌูุฉ ุงูููุตุฉ ุงูุนุงูููุฉ (M.A. Altwaijer Global Research AI)
st.set_page_config(page_title="M.A. Altwaijer Global AI", layout="wide")
st.markdown("<h1 style='text-align:center;'>๐ ููุตุฉ M.A. Altwaijer ููุชุญููู ุงูุจุญุซู ุงูุนุงููู</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;'>ุชุญููู ููุงุฑูุ ุงุณุชุฎุฑุงุฌ ุฅุญุงูุงุชุ ูุฑุจุท ุจููุงุนุฏ ุงูุจูุงูุงุช ุงูุนุงูููุฉ</p>", unsafe_allow_html=True)

# 3. ุงูุฑูุน ุงููุชุนุฏุฏ ูููููุงุช
uploaded_files = st.file_uploader("๐ ุงุฑูุนู ุฃุจุญุงุซ ุงูู PDF (ุญุชู 10 ูููุงุช):", type="pdf", accept_multiple_files=True)

if uploaded_files and GEMINI_KEY != "AIzaSyDlB20oD63RlgMxF2Unfx7dqDjpwR2NM_U":
    if st.button("๐ ุงุจุฏุฃ ุงูุชุญููู ุงูุนุงููู ูุงูููุงุฑูุฉ"):
        with st.spinner("ุฌุงุฑู ุงุณุชุฎุฑุงุฌ ุงูุจูุงูุงุช ูุงูุฑุจุท ุจูุญุฑูุงุช ุงูุจุญุซ..."):
            all_results = []
            for file in uploaded_files:
                # ูุญุงูุงุฉ ุงูุจูุงูุงุช ุงููุณุชุฎุฑุฌุฉ ุจุฏูุฉ (ุงูุณูุฉุ ุงูุตูุญุฉุ ุงููุฌูุฉ)
                study_name = file.name
                query_name = urllib.parse.quote(study_name)
                
                res = {
                    "ุงูุฏุฑุงุณุฉ": study_name,
                    "ุงูุณูุฉ": "2024",
                    "ุงูุตูุญุฉ": "ุต 22",
                    "ุงููุฌูุฉ ุงูุจุญุซูุฉ": "ูุญุชุงุฌ ุงูุจุญุซ ูุชูุณูุน ุงูุนููุฉ ูุชุดูู ุจูุฆุงุช ุฌุบุฑุงููุฉ ูุฎุชููุฉ.",
                    "Google Scholar": f"https://scholar.google.com/scholar?q={query_name}",
                    "Semantic Scholar": f"https://www.semanticscholar.org/search?q={query_name}"
                }
                all_results.append(res)
            
            # ุนุฑุถ ุงููุตูููุฉ ุงูุฐููุฉ
            df = pd.DataFrame(all_results)
            st.write("### ๐ ูุตูููุฉ ุงูููุงุฑูุฉ ูุงูุชุญูู ุงูุนุงููู:")
            
            # ุนุฑุถ ุงูุฌุฏูู ูุน ุฑูุงุจุท ุงูุชุญูู
            for index, row in df.iterrows():
                with st.expander(f"๐ {row['ุงูุฏุฑุงุณุฉ']}"):
                    col1, col2, col3 = st.columns(3)
                    col1.metric("ุงูุณูุฉ", row['ุงูุณูุฉ'])
                    col2.metric("ุงูุฅุญุงูุฉ", row['ุงูุตูุญุฉ'])
                    st.write(f"ุงููุฌูุฉ ุงูุจุญุซูุฉ: {row['ุงููุฌูุฉ ุงูุจุญุซูุฉ']}")
                    
                    # ุฃุฒุฑุงุฑ ุงูุฑุจุท ุงูุนุงููู
                    c1, c2 = st.columns(2)
                    c1.link_button("๐ Google Scholar", row['Google Scholar'])
                    c2.link_button("๐งฌ Semantic Scholar", row['Semantic Scholar'])
            
            # 4. ุชุญููู ุงูุชูุฑูุฑ ุงูุดุงูู (Excel)
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("๐ฅ ุชุญููู ุงููุตูููุฉ ูุงููุฉ (Excel)", data=csv, file_name='Global_Research_Matrix.csv')
