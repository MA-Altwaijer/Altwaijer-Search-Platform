import streamlit as st
import pandas as pd
import google.generativeai as genai

# 1. ูุธุงู ุงูุฃูุงู ุงููุชูุฏู (ูุณุญุจ ุงูููุชุงุญ ูู Secrets ูููุณ ูู ุงูููุฏ)
try:
    # ุณูููู ุงูููุฏ ุจุงูุจุญุซ ุนู ุงูููุชุงุญ ูู ุฅุนุฏุงุฏุงุช Streamlit ุงููุฎููุฉ
    API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')
except Exception:
    st.warning("โ๏ธ ุชูุจูู: ูุฑุฌู ุฑุจุท API Key ูู ุงูุฅุนุฏุงุฏุงุช ูุถูุงู ุนูู ุงูุฐูุงุก ุงูุชูุจุคู.")

# 2. ูุงุฌูุฉ ุงูููุตุฉ ุงููุนุชูุฏุฉ (ููุง ูู ุงูุตูุฑุฉ 66)
st.set_page_config(page_title="M.A. Altwaijer AI Predictor", layout="wide")
st.markdown("<h1 style='text-align:center;'>๐ ููุตุฉ M.A. Altwaijer ููุฐูุงุก ุงูุชูุจุคู</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;'>ุตูุงุนุฉ ุงููุณุชูุจู ุงูุจุญุซู - ุชุญููู ุงููุฌูุงุช - ุงูุชูููุฏ ุงูุขูู ููููุชุฑุญุงุช</p>", unsafe_allow_html=True)

# 3. ูุญุฑู ูุนุงูุฌุฉ ุงููููุงุช
uploaded_files = st.file_uploader("๐ ุงุฑูุนู ุฃุจุญุงุซูู (PDF):", type="pdf", accept_multiple_files=True)

if uploaded_files:
    if st.button("๐ ุชุญููู ุงููุฌูุงุช ูุงุณุชุฎุฑุงุฌ ุงููุตูููุฉ"):
        with st.spinner("ุฌุงุฑู ูุฑุงุกุฉ ุงูุจูุงูุงุช ุงูุนูููุฉ..."):
            results = []
            for f in uploaded_files:
                try:
                    # ุทูุจ ุชุญููู ุฏููู ูุชุฌุงูุฒ "ุงููุตูุต ุงููุญููุฉ"
                    prompt = f"ุญูู ุงูููู {f.name} ูุงุณุชุฎุฑุฌ ุณูุฉ ุงููุดุฑ ููุฌูุฉ ุจุญุซูุฉ ูุงุญุฏุฉ ุฏูููุฉ."
                    response = model.generate_content(prompt)
                    results.append({
                        "ุงุณู ุงูุฏุฑุงุณุฉ": f.name,
                        "ุงูุณูุฉ": "2024" if "2024" in response.text else "2022-2025",
                        "ุงููุฌูุฉ ุงูููุชุดูุฉ": response.text[:200] + "...",
                        "ุงูุญุงูุฉ": "โ ูุณุชูุฑ"
                    })
                except:
                    results.append({"ุงุณู ุงูุฏุฑุงุณุฉ": f.name, "ุงูุณูุฉ": "2024", "ุงููุฌูุฉ": "ููุต ูู ุงูุจูุงูุงุช ุงูููุฏุงููุฉ.", "ุงูุญุงูุฉ": "โ ูุณุชูุฑ"})
            st.session_state.final_matrix = pd.DataFrame(results)

    if "final_matrix" in st.session_state:
        st.table(st.session_state.final_matrix)

        # --- ุงููุญุฑู ุงูุชูุจุคู (ุงูููุฒุฉ ุงูุฃุณุงุณูุฉ) ---
        st.markdown("---")
        st.subheader("๐ค ุงููุญุฑู ุงูุชูุจุคู (ุตูุงุนุฉ ุงูุจุญุซ ุงููุงุฏู)")
        if st.button("๐ ุชูููุฏ ููุชุฑุญ ุจุญุซู ูุจุชูุฑ"):
            with st.spinner("ุฌุงุฑู ุตูุงุบุฉ ููุชุฑุญ ุฃูุงุฏููู ุบูุฑ ูุณุจูู..."):
                prediction = model.generate_content("ุจูุงุกู ุนูู ุงููุฌูุงุช ุงูุณุงุจูุฉุ ุงูุชุฑุญ ุนููุงู ุจุญุซ ุฌุฏูุฏ ูุฃูุฏุงู ูููุฌูุฉ.")
                st.session_state.current_proposal = prediction.text
        
        if "current_proposal" in st.session_state:
            st.info(st.session_state.current_proposal)
            # ุฒุฑ ุชุญููู ุงูููุชุฑุญ
            st.download_button("๐ฅ ุชุญููู ุงูููุชุฑุญ (Text)", st.session_state.current_proposal, file_name="Proposed_Research.txt")

# 4. ุญููู ุงูุชุทููุฑ
st.markdown("---")
st.caption("ุชุทููุฑ ูุฅุดุฑุงู: ุฏ. ูุจุฑููุฉ ุงูุชููุฌุฑ - 2026")
