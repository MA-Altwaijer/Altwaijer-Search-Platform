import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader

# 1. ุงูุฑุจุท ุงูุขูู ุจุฎุฒูุฉ ุงูุฃุณุฑุงุฑ (ูุฅุตูุงุญ ุฎุทุฃ NotFound)
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
    # ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุญุฏุซ
    model = genai.GenerativeModel('gemini-1.5-flash') 
except Exception as e:
    st.error("โ๏ธ ุชุฃูุฏู ูู ุญูุธ ุงูููุชุงุญ ูู ุดุงุดุฉ Secrets ุจุงุณู GEMINI_API_KEY")

st.set_page_config(page_title="Altwaijer Hub", layout="wide")
st.markdown("<h1 style='text-align:center; color: #1E3A8A;'>๐๏ธ ููุตุฉ M.A. Altwaijer ููุชููุฒ ูุงูุงุจุชูุงุฑ</h1>", unsafe_allow_html=True)

# ุฏุงูุฉ ุงุณุชุฎุฑุงุฌ ุงููุต ูู ุงููุฑุงุฌุน ุงูุนุฑุจูุฉ
def extract_text(files):
    text = ""
    for f in files:
        reader = PdfReader(f)
        for page in reader.pages[:5]: # ุชุญููู ุฃูู 5 ุตูุญุงุช ูุถูุงู ุงูุฏูุฉ
            text += page.extract_text()
    return text

# ุงููุงุฌูุฉ ููุง ุชุธูุฑ ูู ุตูุฑุชู
st.sidebar.header("๐ฏ ูุณุงุฑ ุจูุงุก ุงูุจุญุซ")
step = st.sidebar.radio("ุงููุฑุงุญู ุงููููุฌูุฉ:", ["ุชุญุฏูุฏ ุงูุนููุงู", "ุตูุงุบุฉ ุงูุฅุทุงุฑ ุงููุธุฑู", "ุชุญููู ุงููุณูุฏุฉ"])

files = st.file_uploader("(PDF) ุงุฑูุนู ุงููุฑุงุฌุน :", type="pdf", accept_multiple_files=True)

if files:
    if st.button("๐ ุงุจุฏุฃ ุงูุชุญููู ุงูุฐูู ุงูุขู"):
        with st.spinner("โณ ุฌุงุฑู ุงุณุชุฎุฑุงุฌ ุงููููุฉ ุงูุจุญุซูุฉ ูู ูููุงุชู..."):
            context = extract_text(files)
            
            if step == "ุชุญุฏูุฏ ุงูุนููุงู":
                st.subheader("๐ก ููุชุฑุญุงุช ุนูุงููู ุจุญุซูุฉ ุฐููุฉ:")
                prompt = f"ุจูุงุกู ุนูู ุงูุฏุฑุงุณุงุช ุงููุฑููุฉ: {context[:5000]}ุ ุงูุชุฑุญ 5 ุนูุงููู ุจุญุซูุฉ ูุจุชูุฑุฉ ููุง ูููุฉ ุนูููุฉ ูุถุงูุฉ."
                response = model.generate_content(prompt)
                st.info(response.text)

            elif step == "ุตูุงุบุฉ ุงูุฅุทุงุฑ ุงููุธุฑู":
                st.subheader("๐ ุตูุงุบุฉ ุฃูุงุฏูููุฉ ููุชุฑุญุฉ:")
                prompt = f"ุญูู ุงูุฏุฑุงุณุงุช ุงูุชุงููุฉ ูุงูุชุจ ุฅุทุงุฑุงู ูุธุฑูุงู ูุชุฑุงุจุทุงู: {context[:5000]}"
                response = model.generate_content(prompt)
                st.write(response.text)
