import streamlit as st
import requests

# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¨Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø®ØªØµØ±
st.set_page_config(page_title="M.A. Altwaijer Platform", page_icon="ğŸ“", layout="wide")

# 2. Ø§Ù„Ù„ØºØ§Øª ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© (ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø§Ø³Ù… Ø¥Ù„Ù‰ M.A. Altwaijer)
texts = {
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
        "title": "ğŸ“ Ù…Ù†ØµØ© M.A. Altwaijer Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ",
        "sub": "Ø¨ÙˆØ§Ø¨Ø© Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù„Ø³Ø§Ù†ÙŠØ§Øª ÙˆÙƒØ§ÙØ© Ø§Ù„Ø¹Ù„ÙˆÙ…",
        "label": "Ø£Ø¯Ø®Ù„ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«:",
        "button": "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„",
        "results": "ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {} Ù…Ø±Ø¬Ø¹Ø§Ù‹ Ø¹Ù„Ù…ÙŠØ§Ù‹",
        "summary": "Ù…Ù„Ø®Øµ Ø§Ù„Ø¨Ø­Ø« / Analysis:",
        "footer": "Ø¥Ø´Ø±Ø§Ù: M.A. Altwaijer - 2026"
    },
    "English": {
        "title": "ğŸ“ M.A. Altwaijer Academic Platform",
        "sub": "Comprehensive Academic Portal for Linguistics & Global Sciences",
        "label": "Enter research topic:",
        "button": "Extract & Analyze Results",
        "results": "Found {} academic references",
        "summary": "Abstract / Summary:",
        "footer": "Supervised by: M.A. Altwaijer - 2026"
    }
}

with st.sidebar:
    lang = st.selectbox("Language / Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])

t = texts[lang]
st.title(t["title"])
st.markdown(f"##### {t['sub']}")
st.divider()

# 3. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø«
query = st.text_input(t["label"], "")

if st.button(t["button"]):
    if query:
        with st.spinner('Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©...'):
            url = f"https://api.openalex.org/works?search={query}"
            try:
                response = requests.get(url)
                data = response.json()
                results = data.get('results', [])
                
                if results:
                    st.success(t["results"].format(data.get('meta', {}).get('count')))
                    for i, paper in enumerate(results[:10], 1):
                        with st.expander(f"ğŸ“„ {i}. {paper.get('display_name')}"):
                            abstract_raw = paper.get('abstract_inverted_index')
                            if abstract_raw:
                                words = {}
                                for word, indices in abstract_raw.items():
                                    for index in indices: words[index] = word
                                abstract_text = ' '.join([words[i] for i in sorted(words.keys())])
                                st.info(f"{t['summary']}\n\n{abstract_text[:800]}...") 
                            else:
                                st.warning("Ø§Ù„Ù…Ù„Ø®Øµ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø±Ù‚Ù…ÙŠØ§Ù‹.")
                            
                            col1, col2 = st.columns([2, 1])
                            with col1:
                                st.write(f"ğŸ“… Ø§Ù„Ø³Ù†Ø©: {paper.get('publication_year')}")
                                st.write(f"ğŸ¢ Ø§Ù„Ù…ØµØ¯Ø±: {paper.get('primary_location', {}).get('source', {}).get('display_name', 'Ù…ØµØ¯Ø± Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ')}")
                            with col2:
                                if paper.get('doi'):
                                    st.link_button("ØªØ­Ù…ÙŠÙ„/Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨Ø­Ø«", paper.get('doi'))
                else:
                    st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬.")
            except:
                st.error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„.")
    else:
        st.warning("ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„Ø¨Ø­Ø«.")

st.markdown("---")
st.caption(t["footer"])
