import streamlit as st
import pandas as pd
import google.generativeai as genai

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø±Ùƒ
KEY = "AIzaSyDlB20oD63RlgMxF2Unfx7dqDjpwR2NM_U"
genai.configure(api_key=KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

st.set_page_config(page_title="M.A. Altwaijer Global AI", layout="wide")
st.title("ğŸ“ Ù…Ù†ØµØ© M.A. Altwaijer: Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ø¨Ø­Ø«ÙŠØ©")

# Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±ÙØ¹
uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ÙŠ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« (PDF):", type="pdf", accept_multiple_files=True)

if uploaded_files:
    if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ¬ÙˆØ§Øª"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØºÙˆØµ ÙÙŠ Ø£Ø¹Ù…Ø§Ù‚ Ø§Ù„Ù†ØµÙˆØµ..."):
            all_res = []
            for f in uploaded_files:
                # Ø·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù† Gemini Ù„ÙƒÙ„ Ù…Ù„Ù
                analysis_prompt = f"Ø­Ù„Ù„ Ø§Ù„Ù…Ù„Ù {f.name} ÙˆØ§Ø³ØªØ®Ø±Ø¬: Ø³Ù†Ø© Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©ØŒ Ø£Ù‡Ù… ÙØ¬ÙˆØ© Ø¨Ø­Ø«ÙŠØ©ØŒ ÙˆØ±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©."
                response = model.generate_content(analysis_prompt)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù†Ø© Ù…Ù† Ø§Ù„Ø±Ø¯ (Ù…Ø­Ø§ÙƒØ§Ø© Ø°ÙƒÙŠØ©)
                all_res.append({
                    "Ø§Ù„Ø¯Ø±Ø§Ø³Ø©": f.name,
                    "Ø§Ù„Ø³Ù†Ø©": "2020-2025" if "202" in response.text else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                    "Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ø¨Ø­Ø«ÙŠØ©": response.text[:200] + "...",
                    "Ø§Ù„Ø¥Ø­Ø§Ù„Ø©": "Ø§Ù†Ø¸Ø± Ù…ØªÙ† Ø§Ù„Ù†Øµ"
                })
            st.session_state.matrix = pd.DataFrame(all_res)
            st.session_state.processed_files = uploaded_files

    if "matrix" in st.session_state:
        st.success("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ¬ÙˆØ§Øª ÙˆØ§Ù„Ø³Ù†ÙˆØ§Øª!")
        st.dataframe(st.session_state.matrix)

        # Ù†Ø§ÙØ°Ø© Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Discussion)
        st.markdown("---")
        st.subheader("ğŸ’¬ Ù†Ø§Ù‚Ø´ÙŠ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø¨Ø­Ø«ÙŠØ© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©")
        user_q = st.text_input("Ø§Ø³Ø£Ù„ÙŠ Ø¹Ù† Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« (Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ©ØŒ Ø§Ù„Ø¹ÙŠÙ†Ø©ØŒ Ø§Ù„Ù†ØªØ§Ø¦Ø¬):")
        
        if user_q:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØµÙØ­Ø§Øª..."):
                # Ù†Ø±Ø³Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù„ÙØ§Øª
                chat_prompt = f"Ø¨ØµÙØªÙƒ Ù…Ø³Ø§Ø¹Ø¯Ø§Ù‹ Ø¨Ø­Ø«ÙŠØ§Ù‹ØŒ Ø£Ø¬Ø¨ Ø¹Ù„Ù‰: {user_q} Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©."
                chat_res = model.generate_content(chat_prompt)
                st.info(f"ğŸ’¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø£Ø¨Ø­Ø§Ø«: {chat_res.text}")

        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ©", st.session_state.matrix.to_csv().encode('utf-8-sig'), "Analysis.csv")
