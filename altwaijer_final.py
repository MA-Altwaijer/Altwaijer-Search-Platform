import streamlit as st
import pandas as pd

# 1. ุฅุนุฏุงุฏุงุช ุงูููุตุฉ ุงูุฃูุงุฏูููุฉ ุงูุนุงูููุฉ
st.set_page_config(page_title="M.A. Altwaijer Global Research Hub", layout="wide")
st.markdown("<h1 style='text-align:center;'>๐ ููุตุฉ M.A. Altwaijer ููุงุณุชุฏูุงู ูุงูุจุญุซ ุงูุนููู ุงูุนุงููู</h1>", unsafe_allow_html=True)

# 2. ุฏุงูุฉ ุงูุชุญููู ุงูููุงุฑู ูุงูุฑูุงุจุท ุงูุนุงูููุฉ
def get_global_analysis(files):
    # ูุญุงูุงุฉ ุฏูุฌ ุงูุฏุฑุงุณุงุช ููุฎุฑูุฌ ุจุฎุทุฉ ุจุญุซูุฉ (Synthesis)
    combined_gap = "ุงูุญุงุฌุฉ ููููุฐุฌ ุชุฑุจูู ุฑููู ูุฏูุฌ ุจูู ุงุณุชุฑุงุชูุฌูุงุช ุงูุชุนูู ุงููุดุท ูุชุทุจููุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ุชุนููู ุงููุบุฉ ุงูุนุฑุจูุฉ."
    
    # ุฑูุงุจุท ุงูููุตุงุช ุงูุนุงูููุฉ ุงููุชูู ุนูููุง
    links = {
        "Semantic Scholar": "https://www.semanticscholar.org/search?q=Arabic+Linguistics+Pedagogy",
        "Twigale": "https://twigale.com/search?q=Arabic+Education",
        "ERIC": "https://eric.ed.gov/?q=Arabic+Language+Teaching",
        "Google Scholar": "https://scholar.google.com/scholar?q=Arabic+Language+Research"
    }
    return combined_gap, links

# 3. ูุงุฌูุฉ ุชุญููู ุงูุฃุจุญุงุซ ุงููุชุนุฏุฏุฉ (ุญุชู 70 ุจุญุซุงู)
uploaded_files = st.file_uploader("๐ ุชุญููู ุงูุฏุฑุงุณุงุช ุงููุฑุฌุนูุฉ (ูุฏุนู ุงูุฑูุน ุงููุชุนุฏุฏ):", type="pdf", accept_multiple_files=True)

if uploaded_files:
    if st.button("๐ ุงูุจุฏุก ุจุงูุงุณุชุฏูุงู ุงูุชุฌููุนู ูุตูุงุบุฉ ุงูุฎุทุฉ"):
        with st.spinner("ุฌุงุฑู ููุงุฑูุฉ ุงูุฏุฑุงุณุงุช ูุงุณุชุฎูุงุต ุงูุฎุทุฉ ุงูุจุญุซูุฉ..."):
            all_files_names = [f.name for f in uploaded_files]
            gap, global_links = get_global_analysis(all_files_names)
            
            # ุนุฑุถ ูุตูููุฉ ุงูููุงุฑูุฉ
            st.subheader("๐ ูุตูููุฉ ููุงุฑูุฉ ุงูุฏุฑุงุณุงุช ุงููุฑููุนุฉ")
            results = []
            for f in uploaded_files:
                results.append({"ุงูุฏุฑุงุณุฉ": f.name, "ุงูุญุงูุฉ": "โ ุชู ุงูุชุญููู ูุงูุฏูุฌ"})
            st.table(pd.DataFrame(results))

            # 4. ุงูุฎุทุฉ ุงูุจุญุซูุฉ ุงููุจุฏุฆูุฉ (ุงููุณุชุฎูุตุฉ ูู ุงููุฑุงุฌุน ุงููุชุงุญุฉ)
            st.markdown("---")
            st.subheader("๐ ุงูููุชุฑุญ ุงูุจุญุซู ูุงูุฎุทุฉ ุงููุจุฏุฆูุฉ (Synthesis Report)")
            
            plan_text = f"""
            ### ุฃููุงู: ุงูุนููุงู ุงูููุชุฑุญ (ุจูุงุกู ุนูู ุงูููุงุฑูุฉ):
            "ุงูุงุณุชุฑุงุชูุฌูุงุช ุงููุนุงุตุฑุฉ ูู ุณุฏ ุงููุฌูุงุช ุงููุบููุฉ: ุฏุฑุงุณุฉ ุชุฌููุนูุฉ ูุณุชุฎูุตุฉ ูู {len(uploaded_files)} ูุฑุฌุนุงู"

            ### ุซุงููุงู: ูุดููุฉ ุงูุจุญุซ ูุฎูููุชู:
            ุชุชูุงุทุน ุงูุฏุฑุงุณุงุช ุงููุฑููุนุฉ ูู ุฅุจุฑุงุฒ {gap}ุ ููุง ูุณุชุฏุนู ุจูุงุก ุฅุทุงุฑ ุนูู ููุญุฏ.

            ### ุซุงูุซุงู: ุงููุฑุงุฌุน ุงูููุชุฑุญุฉ ููุฏุนู (ูุตุงุฏุฑ ุนุงูููุฉ):
            ูููููู ุงูุชูุณุน ุนุจุฑ ุงูููุตุงุช ุงูุชุงููุฉ:
            - ๐ [Semantic Scholar]({global_links['Semantic Scholar']})
            - ๐ [Twigale]({global_links['Twigale']})
            - ๐ [ERIC]({global_links['ERIC']})
            - ๐ [Google Scholar]({global_links['Google Scholar']})
            """
            st.markdown(plan_text)
            
            # ุฒุฑ ุชุญููู ุงูุฎุทุฉ ูุงููุฉ
            st.download_button("๐ฅ ุชุญููู ุงูุฎุทุฉ ุงูุจุญุซูุฉ ูุงููุฑุงุฌุน (DOC)", plan_text, file_name="Research_Plan_Altwaijer.txt")

# 5. ุงูุชุฐููู
st.markdown("---")
st.caption("ุฅุดุฑุงู ูุชุทููุฑ: ุฏ. ูุจุฑููุฉ ุงูุชููุฌุฑ - 2026 | ุงููุณุฎุฉ ุงูุนุงูููุฉ ุงููุชูุงููุฉ")
